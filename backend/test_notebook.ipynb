{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63650dc7",
   "metadata": {},
   "source": [
    "# Test Tools and Models\n",
    "\n",
    "## Running this notebook\n",
    "\n",
    "To run this in VS Code:\n",
    "1. Open a terminal\n",
    "2. Navigate to `./backend`\n",
    "3. Configure poetry to set up a venv environment by running `poetry config virtualenvs.in-project true`\n",
    "4. Remove any existing poetry venv by running `poetry remove --all`\n",
    "5. Run `poetry install` to install the dependencies in the virtual environment\n",
    "6. In Select Kernel dropdown in the top right corner of VS Code, select `Python Environments` and select the venv environment you created at `backend/.venv/bin/python`\n",
    "7. Run the notebook by clicking on the play button in the top right corner of VS Code or running `jupyter notebook test_notebook.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Get the absolute path to the src directory\n",
    "src_path = os.path.abspath('src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('src/.env')\n",
    "os.environ['MILVUS_HOST'] = 'localhost'\n",
    "os.environ['OLLAMA_HOST'] = 'localhost'\n",
    "from src.models import get_model, bind_tools, handle_tool_call, handle_streaming_tool_call\n",
    "from src.tools import retrieve_context, multiply\n",
    "from src.langgraph_agent import create_agent_graph, run_agent_graph, run_agent_graph_streaming\n",
    "from src.app import ChatRequest, prompt_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_notebook.ipynb (Revised)\n",
    "\n",
    "assistant_system_prompt = prompt_templates[\"assistant_system_prompt\"]\n",
    "tools = [multiply, retrieve_context]\n",
    "agent_graph = create_agent_graph(tools, assistant_system_prompt)\n",
    "user_prompt = \"What is the phone number for DataNinja Support?\"\n",
    "\n",
    "async def stream_generator(agent_graph, user_prompt):\n",
    "    try:\n",
    "        async for chunk in run_agent_graph_streaming(agent_graph, user_prompt):\n",
    "            if chunk:\n",
    "                yield f\"data: {json.dumps({'content': chunk})}\\n\\n\"\n",
    "    except Exception as e:\n",
    "        yield f\"data: {json.dumps({'error': str(e)})}\\n\\n\"\n",
    "    finally:\n",
    "        yield \"data: [DONE]\\n\\n\"\n",
    "\n",
    "async def test_agent_graph_streaming():\n",
    "    async for chunk in stream_generator(agent_graph, user_prompt):\n",
    "        print(chunk)\n",
    "\n",
    "# Execute the test in Jupyter:\n",
    "await test_agent_graph_streaming()  # Use await in a Jupyter cell or use %async magic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
